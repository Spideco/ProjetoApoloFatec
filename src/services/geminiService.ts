import { GoogleGenerativeAI } from '@google/generative-ai';

export class GeminiService {
  private genAI: GoogleGenerativeAI;
  private model: any;

  constructor() {
    this.genAI = new GoogleGenerativeAI('AIzaSyDfdwmofon0Gi2t0J2FUrbtXA2tIfF7UR4');
    this.model = this.genAI.getGenerativeModel({ 
      model: 'gemini-2.5-flash-preview-09-2025',
      generationConfig: {
        temperature: 0.7,
        topP: 0.9, // Aumentado para melhor coer√™ncia
        topK: 40,
        maxOutputTokens: 2048,
      },
    });
  }

  async generateResponse(messages: Array<{text: string, isUser: boolean}>): Promise<string> {
    try {
      const systemPrompt = `Voc√™ √© o "Apolo", um assistente educacional especializado em prepara√ß√£o para o ENEM (Exame Nacional do Ensino M√©dio). Suas caracter√≠sticas:

üìö ESPECIALIDADES:
- Todas as disciplinas do ENEM (Matem√°tica, Portugu√™s, Ci√™ncias da Natureza, Ci√™ncias Humanas, Reda√ß√£o)
- Metodologias de estudo eficazes
- Estrat√©gias de prova e gest√£o de tempo
- An√°lise de quest√µes anteriores do ENEM

üéØ ESTILO DE RESPOSTA:
- Did√°tica e clara, adaptada ao n√≠vel do estudante
- Use exemplos pr√°ticos e analogias quando necess√°rio
- Estruture respostas com t√≥picos e subt√≥picos quando apropriado
- Inclua dicas espec√≠ficas para o ENEM quando relevante
- Seja encorajadora e motivacional

üß† CONTINUIDADE DA CONVERSA:
- Sempre fa√ßa refer√™ncia ao que foi discutido anteriormente quando relevante
- Use express√µes como "Como mencionamos antes...", "Lembra que voc√™ disse...", "Continuando..."
- Se o estudante fizer uma pergunta relacionada a algo j√° discutido, conecte os conceitos
- Mantenha um tom de conversa cont√≠nua, n√£o trate cada pergunta isoladamente
- Construa em cima do conhecimento j√° compartilhado na conversa

üìù FORMATO:
- Use markdown para formata√ß√£o (negrito, listas, etc.)
- Mantenha um tom professoral, mas acess√≠vel
- Termine sempre com uma pergunta ou sugest√£o de pr√≥ximo passo`;

      // Converter mensagens para o formato estruturado do Gemini Chat API
      const contents = [];
      
      // Se for a primeira mensagem, incluir o system prompt
      if (messages.length === 1 && messages[0].isUser) {
        contents.push({
          role: "user",
          parts: [{ text: `${systemPrompt}\n\n${messages[0].text}` }]
        });
      } else {
        // Para conversas j√° iniciadas, converter hist√≥rico completo
        for (let i = 0; i < messages.length; i++) {
          const msg = messages[i];
          const role = msg.isUser ? "user" : "model";
          
          // Se houver duas mensagens seguidas do mesmo role, mesclar
          if (contents.length > 0 && contents[contents.length - 1].role === role) {
            contents[contents.length - 1].parts[0].text += `\n\n${msg.text}`;
          } else {
            contents.push({
              role: role,
              parts: [{ text: msg.text }]
            });
          }
        }
        
        // Se a primeira mensagem n√£o incluir o system prompt, adicionar
        if (contents[0]?.role === "user" && !contents[0].parts[0].text.includes(systemPrompt)) {
          contents[0].parts[0].text = `${systemPrompt}\n\n${contents[0].parts[0].text}`;
        }
      }

      const result = await this.model.generateContent({ contents });
      const response = await result.response;
      return response.text();
    } catch (error) {
      console.error('Erro ao gerar resposta com Gemini:', error);
      throw new Error('Erro ao comunicar com a IA. Verifique sua chave da API.');
    }
  }
}